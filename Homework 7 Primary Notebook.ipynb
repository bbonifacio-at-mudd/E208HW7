{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "782c5184",
   "metadata": {},
   "source": [
    "# Team Viviane Solomon and Brandon Bonifacio\n",
    "# How We Split Up The Work: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb418d86",
   "metadata": {},
   "source": [
    "# HW7: Train a Sequence Classifier That Can Predict if a Sentence is in English or Spanish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872fa546",
   "metadata": {},
   "source": [
    "The goal of this assignment is to train a sequence classifier that can predict if a sentence is in \n",
    "English or Spanish. You should use the official PyTorch documentation to build your system \n",
    "from scratch. You may use other online sources as well but must cite your sources and indicate \n",
    "clearly what portions of your code have been copied and modified from elsewhere. You may \n",
    "work individually or with a partner on this assignment.\n",
    "\n",
    "\n",
    "Each team should submit one assignment as a single jupyter notebook on Sakai. At the top of \n",
    "your notebook, please indicate both team members’ names and who did what. To speed up \n",
    "training, you may want to run your jupyter notebook in Google Colab with a GPU. Note: The \n",
    "datasets provided below are very large, and you don’t need to train on everything!\n",
    "\n",
    "In fact, as you develop your code, I would recommend using a tiny subset of data to iterate quickly, and \n",
    "wait until your code is debugged to start training on larger subsets of data. It is much better to \n",
    "have a functioning model that is trained on 1% of the data than a non-functional model that \n",
    "failed to train on 100% of the data.\n",
    "\n",
    "An additional 10 points will be graded for the organization and clarity of your notebook. Your \n",
    "notebook should read like a tutorial and be understandable to others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae9c53f",
   "metadata": {},
   "source": [
    "## Part 1: Basic System with fixed-length inputs (65 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f0bed",
   "metadata": {},
   "source": [
    "In the first part of the assignment you will do the following:\n",
    "\n",
    "\n",
    "● Prepare the data (20 points). Get two large text files: one English file (WikiText-103, \n",
    "181MB) and one Spanish file (e.g. Spanish text corpus, 155MB). Convert to lowercase \n",
    "and remove all punctuation except “.” so the data only contains alphabet characters, \n",
    "whitespace, and periods. Determine a set of unique characters and map all characters \n",
    "to integers. Split the data into train & validation sets, and split each into chunks of fixed \n",
    "length.\n",
    "\n",
    "\n",
    "● Train 1-layer model (20 Points). Define an LSTM model containing 1 LSTM layer \n",
    "followed by an output linear layer. Your model should classify a fixed-length sequence \n",
    "of characters as English or Spanish. Show your training & validation loss curves, along \n",
    "with your validation classification accuracy.\n",
    "\n",
    "\n",
    "● Experimentation (20 points). Experiment with different aspects of the model: the \n",
    "number of LSTM layers, the number of fully connected layers, the size of the hidden \n",
    "layer, etc. Train the corresponding models, compare their performance, and provide \n",
    "plots to demonstrate the effect of at least two different hyperparameters of interest.\n",
    "\n",
    "\n",
    "● Intuition (5 points). Show the output of your model for several specific sentences. Pick \n",
    "inputs that demonstrate the behavior of the system, and try to figure out what things \n",
    "the model is focusing on. Explain your intuition about what the model is doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f200d568",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Welcome to our Tutorial for ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1c7571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae82b160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5624a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4a20e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e1713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bed8be30",
   "metadata": {},
   "source": [
    "## Part 2: Realistic system with variable-length inputs (25 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd17841c",
   "metadata": {},
   "source": [
    "In the second part of the assignment you will do the following:\n",
    "\n",
    "\n",
    "● Prepare the data (10 points). Your data should be the same as in part 1, except that \n",
    "each sample should contain one complete sentence rather than a fixed-length sequence of characters. This means that your training & validation samples should have variable \n",
    "length. You will need to zero-pad your inputs.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923bf8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc9c16f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ffd359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324c1fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6574aab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea53aed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767afeb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8605e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf80d4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23d472c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
