{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "549eaa6d",
   "metadata": {},
   "source": [
    "# Team Viviane Solomon and Brandon Bonifacio\n",
    "# How We Split Up The Work: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b99cc3",
   "metadata": {},
   "source": [
    "# HW7: Train a Sequence Classifier That Can Predict if a Sentence is in English or Spanish."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480a01c0",
   "metadata": {},
   "source": [
    "The goal of this assignment is to train a sequence classifier that can predict if a sentence is in \n",
    "English or Spanish. You should use the official PyTorch documentation to build your system \n",
    "from scratch. You may use other online sources as well but must cite your sources and indicate \n",
    "clearly what portions of your code have been copied and modified from elsewhere. You may \n",
    "work individually or with a partner on this assignment.\n",
    "\n",
    "\n",
    "Each team should submit one assignment as a single jupyter notebook on Sakai. At the top of \n",
    "your notebook, please indicate both team members’ names and who did what. To speed up \n",
    "training, you may want to run your jupyter notebook in Google Colab with a GPU. Note: The \n",
    "datasets provided below are very large, and you don’t need to train on everything!\n",
    "\n",
    "In fact, as you develop your code, I would recommend using a tiny subset of data to iterate quickly, and \n",
    "wait until your code is debugged to start training on larger subsets of data. It is much better to \n",
    "have a functioning model that is trained on 1% of the data than a non-functional model that \n",
    "failed to train on 100% of the data.\n",
    "\n",
    "An additional 10 points will be graded for the organization and clarity of your notebook. Your \n",
    "notebook should read like a tutorial and be understandable to others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d381d41c",
   "metadata": {},
   "source": [
    "## Part 1: Basic System with fixed-length inputs (65 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f5793",
   "metadata": {},
   "source": [
    "In the first part of the assignment you will do the following:\n",
    "\n",
    "\n",
    "● Prepare the data (20 points). Get two large text files: one English file (WikiText-103, \n",
    "181MB) and one Spanish file (e.g. Spanish text corpus, 155MB). Convert to lowercase \n",
    "and remove all punctuation except “.” so the data only contains alphabet characters, \n",
    "whitespace, and periods. Determine a set of unique characters and map all characters \n",
    "to integers. Split the data into train & validation sets, and split each into chunks of fixed \n",
    "length.\n",
    "\n",
    "\n",
    "● Train 1-layer model (20 Points). Define an LSTM model containing 1 LSTM layer \n",
    "followed by an output linear layer. Your model should classify a fixed-length sequence \n",
    "of characters as English or Spanish. Show your training & validation loss curves, along \n",
    "with your validation classification accuracy.\n",
    "\n",
    "\n",
    "● Experimentation (20 points). Experiment with different aspects of the model: the \n",
    "number of LSTM layers, the number of fully connected layers, the size of the hidden \n",
    "layer, etc. Train the corresponding models, compare their performance, and provide \n",
    "plots to demonstrate the effect of at least two different hyperparameters of interest.\n",
    "\n",
    "\n",
    "● Intuition (5 points). Show the output of your model for several specific sentences. Pick \n",
    "inputs that demonstrate the behavior of the system, and try to figure out what things \n",
    "the model is focusing on. Explain your intuition about what the model is doing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b61763",
   "metadata": {},
   "source": [
    "## Welcome to our Tutorial for Preparing the Data! \n",
    "\n",
    "### In the cell below, we go through the process of converting the text to lowercase and removing all punctuation except \".\" so the data only contains alphabet characters, whitespace, and periods for the Spanish Sentences. We also save this locally so we don't have to do this every time we load the file.\n",
    "\n",
    "To provide an example for what we want to do with this data, we provide the first few sentences from the Spanish sentences.txt file. \n",
    "\n",
    "*la enciclopedia libre Jorge Hess De Wikipedia#\n",
    "\n",
    "*la enciclopedia libre Saltar a Jorge Hess de julio es un y cofundador de la Liga Argentina de Esperanto Hess escribió un manual para el aprendizaje de esperanto que fue editado por primera vez en y se titula Sabe Usted Esperanto#\n",
    "\n",
    "*Es uno de los más conocidos libros en español que tratan sobre el tema junto con Curso Práctico de Esperanto Ferenc Szilágyi#\n",
    "\n",
    "*el cual Hess adaptó para los en#\n",
    "\n",
    "\n",
    "## As you can see, each sentence begins with an aserisk (*), and it ends with a hashtag and a new-line character (#\\n) After this function, these sentences in the txt file should look like: \n",
    "\n",
    "la enciclopedia libre jorge hess de wikipedia\n",
    "\n",
    "la enciclopedia libre saltar a jorge hess de julio es un y cofundador de la liga argentina de esperanto hess escribió un manual para el aprendizaje de esperanto que fue editado por primera vez en y se titula sabe usted esperanto\n",
    "\n",
    "es uno de los más conocidos libros en español que tratan sobre el tema junto con curso práctico de esperanto ferenc szilágyi\n",
    "\n",
    "el cual hess adaptó para los en\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e09ea414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Statements\n",
    "from tqdm import tqdm\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61c004e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "áéíóúñü áéíóúñü.\n",
      "ÁÉÍÓÚÑÜ ÁÉÍÓÚÑÜ.\n"
     ]
    }
   ],
   "source": [
    "## There is an important aspect of Spanish sentences we must consider. Python is mostly an English-based language, \n",
    "## so it is possible that Python might miss the diacriticed characters, namely é, á, í, ó, ú, ñ, and ü. However, \n",
    "## thankfully the Python devs have already thought of this, so we don't have to worry about it. However, we will continually\n",
    "## check this throughout the process to make sure this is working as intended. \n",
    "## An example of Python functions working with Spanish characters is provided in the cell below. \n",
    "\n",
    "#Example of Python working with Spanish Characters - Python can work with Spanish!\n",
    "espanol = \"ÁÉÍÓÚÑÜ áéíóúñü.\"\n",
    "print(espanol.lower())  \n",
    "print(espanol.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52f6ae67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi  my  name .... is brandón bonifacío. . . \n"
     ]
    }
   ],
   "source": [
    "#Here, we make the process helper function to process a single sentence according to the problem\n",
    "##Below, we convert the text in this file to lowercase, remove all punctuation except \".\"\n",
    "def process(sentence):\n",
    "    \"\"\"\n",
    "    Processes the given sentence string according to what the problem wants us to do:\n",
    "    - Convert all characters to lowercase.\n",
    "    - Remove all punctuation except \".\". Keep whitespace characters (\"\\n\" and \" \", idk any others)\n",
    "    \"\"\"\n",
    "    sentence = sentence.lower() #convert all characters to lowercase, O(n) time \n",
    "    \n",
    "    #https://datagy.io/python-remove-punctuation-from-string/\n",
    "    #https://docs.python.org/3/library/string.html\n",
    "    \n",
    "    #Here, we make a translator that will replace all punctuation EXCEPT \".\" to the empty string (get rid of them)\n",
    "    #string.punctuation is list of punctuations, removing \".\"\n",
    "    punctuations_without_period = string.punctuation.replace(\".\", \"\")\n",
    "    translator = str.maketrans('', '', punctuations_without_period)\n",
    "    return sentence.translate(translator)\n",
    "\n",
    "test_string = \"Hi #%@ my #$% name ..,,.,. !is BRANDÓN Bonifacío. .@#$@$--=!~` . \"\n",
    "print(process(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "448f084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing sentences: 100%|██████████████████████████████████████████████| 6075660/6075660 [00:46<00:00, 129433.35it/s]\n",
      "Writing to file: 100%|███████████████████████████████████████████████████| 6075660/6075660 [00:09<00:00, 649456.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processing complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## sentences.txt is our file of Spanish sentences. \n",
    "## With respect to this Jupyter Notebook's directory, this raw file is stored in (for Brandon's computer): \n",
    "## /Users\\Brandon\\Desktop\\Classes\\E208\\Homework\\E208HW7\\Data\\Raw\\Spanish/sentences.txt\n",
    "\n",
    "## After processing this data, we store it in \n",
    "## /E208/E208HW7/Data/Raw/Spanish/processed_spanish.txt\n",
    "\n",
    "## AS AN IMPORTANT NOTE, THIS CELL SHOULD ONLY BE RUN ONCE. \n",
    "## UNCOMMENT THE CODE BELOW TO RUN IT:\n",
    "# Windows: Ctrl + / \n",
    "# Mac: Cmd + /\n",
    "\n",
    "\n",
    "# # Path to the raw data\n",
    "# input_path = \"/Users\\Brandon\\Desktop\\Classes\\E208\\Homework\\E208HW7\\Data\\Raw\\Spanish/sentences.txt\"\n",
    "# # Path to the processed data\n",
    "# output_path = \"/Users\\Brandon\\Desktop\\Classes\\E208\\Homework\\E208HW7\\Data\\Processed\\Spanish/sentences.txt\"\n",
    "\n",
    "# #Open the input file and take out the sentences\n",
    "# #https://stackoverflow.com/questions/2081836/how-to-read-specific-lines-from-a-file-by-line-number\n",
    "# with open(input_path, \"r\") as file:\n",
    "#     raw_sentences = file.readlines()\n",
    "\n",
    "# #Process each sentence\n",
    "# processed_sentences = []\n",
    "# for sentence in tqdm(raw_sentences, desc=\"Processing sentences\"):\n",
    "#     if sentence.startswith('*') and sentence.endswith(\"#\\n\"): #Every sentence had a * in front of it and the end character at the end\n",
    "#         processed_sentences.append(process(sentence[1:-2]))\n",
    "#     else:\n",
    "#         print(f\"Something went wrong! Here's the current sentence: {sentence}\")\n",
    "#         raise\n",
    "\n",
    "# #Now write the processed sentences to the output file\n",
    "# with open(output_path, \"w\") as file:\n",
    "#     for sentence in tqdm(processed_sentences, desc=\"Writing to file\"):\n",
    "#         file.write(sentence + \"\\n\") #Add new line whitespace at the end of each sentence\n",
    "\n",
    "# print(\"Data processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904f4ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b4459b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e108af8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d063443c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff38a60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17a3d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "356b0e1e",
   "metadata": {},
   "source": [
    "## Part 2: Realistic system with variable-length inputs (25 points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb035d2",
   "metadata": {},
   "source": [
    "In the second part of the assignment you will do the following:\n",
    "\n",
    "\n",
    "● Prepare the data (10 points). Your data should be the same as in part 1, except that \n",
    "each sample should contain one complete sentence rather than a fixed-length sequence of characters. This means that your training & validation samples should have variable \n",
    "length. You will need to zero-pad your inputs.\n",
    "\n",
    "\n",
    "● Train model (15 points). Use the best model architecture that you found from part 1, \n",
    "and train a model on your data. Be careful to handle the zero-padding correctly, since \n",
    "you can no longer use the same index for all batch samples. Show the training & \n",
    "validation loss curves and validation accuracy. Compare your results to the \n",
    "corresponding model in part 1.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c19ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f32d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e0604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92dfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a03f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90fa2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b545d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65c34f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ffda3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82122b22",
   "metadata": {},
   "source": [
    "Running List of Resources Used: \n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/20935151/how-to-encode-and-decode-from-spanish-in-python\n",
    "\n",
    "https://datagy.io/python-remove-punctuation-from-string/\"\n",
    "\n",
    "https://stackoverflow.com/questions/2081836/how-to-read-specific-lines-from-a-file-by-line-number\n",
    "\n",
    "https://docs.python.org/3/library/string.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a3e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
